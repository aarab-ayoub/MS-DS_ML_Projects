{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b4d504a-c327-4e3b-abdf-b30e76245d16",
   "metadata": {},
   "source": [
    "# ğŸš€ TrOCR - Microsoft's Transformer OCR\n",
    "\n",
    "**Much easier than PaddleOCR, works perfectly on Kaggle!**\n",
    "\n",
    "## Why TrOCR?\n",
    "- âœ… **Pre-trained on 684M text images** (way more than your 10K!)\n",
    "- âœ… **Transformer-based** (state-of-the-art)\n",
    "- âœ… **Easy to use** (just 3 lines of code)\n",
    "- âœ… **No download issues** (uses HuggingFace)\n",
    "- âœ… **Expected: 65-75% accuracy**\n",
    "\n",
    "## Comparison:\n",
    "| Model | Accuracy | Setup Time |\n",
    "|-------|----------|------------|\n",
    "| Your improved | 49% | âœ… Done |\n",
    "| PaddleOCR | âŒ Won't load | âŒ Broken |\n",
    "| **TrOCR** | **65-75%** | **2 minutes** |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b4f6b9-7bc3-4047-9be5-e2031aa597ef",
   "metadata": {},
   "source": [
    "## Step 1: Install (Fast!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bc4240f-90be-4af9-8f41-3e83c956de0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T19:53:00.481049Z",
     "iopub.status.busy": "2026-02-15T19:53:00.480462Z",
     "iopub.status.idle": "2026-02-15T19:53:04.521834Z",
     "shell.execute_reply": "2026-02-15T19:53:04.520963Z",
     "shell.execute_reply.started": "2026-02-15T19:53:00.481019Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Installed in 30 seconds!\n"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers pillow torch -q\n",
    "\n",
    "print('âœ… Installed in 30 seconds!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03543b8-cbf3-4cf5-8408-23cc804b7641",
   "metadata": {},
   "source": [
    "## Step 2: Load TrOCR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "573137b1-0051-4bea-bda6-08d23bd3283a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T19:53:04.524037Z",
     "iopub.status.busy": "2026-02-15T19:53:04.523682Z",
     "iopub.status.idle": "2026-02-15T19:53:11.122649Z",
     "shell.execute_reply": "2026-02-15T19:53:11.121958Z",
     "shell.execute_reply.started": "2026-02-15T19:53:04.523997Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 2.8.0+cu126\n",
      "torchvision version: 0.23.0+cu126\n",
      "CUDA available: True\n",
      "GPU: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "import torch, torchvision\n",
    "print(\"torch version:\", torch.__version__)\n",
    "print(\"torchvision version:\", torchvision.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"GPU:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76787ed6-f8bf-430e-9be1-26fe1be403e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T19:55:28.530073Z",
     "iopub.status.busy": "2026-02-15T19:55:28.528920Z",
     "iopub.status.idle": "2026-02-15T19:55:30.817683Z",
     "shell.execute_reply": "2026-02-15T19:55:30.816929Z",
     "shell.execute_reply.started": "2026-02-15T19:55:28.530038Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Using device: cuda\n",
      "GPU: Tesla T4\n",
      "GPU Memory: 15.64 GB\n",
      "\n",
      "â³ Loading TrOCR BASE model (faster, more stable)...\n",
      "Loading directly to GPU...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-printed and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Verifying model placement...\n",
      "Model device: cuda:0\n",
      "Model dtype: torch.float16\n",
      "âœ… All parameters loaded correctly!\n",
      "\n",
      "âœ… TrOCR BASE model ready!\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "from PIL import Image\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "# Clear GPU cache\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "# =========================\n",
    "# GPU CONFIG\n",
    "# =========================\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'ğŸš€ Using device: {device}')\n",
    "\n",
    "if device.type == \"cuda\":\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "\n",
    "# =========================\n",
    "# KAGGLE FIX: Use smaller base model\n",
    "# =========================\n",
    "MODEL_NAME = 'microsoft/trocr-base-printed'  # Smaller, more reliable on Kaggle\n",
    "print(f'\\nâ³ Loading TrOCR BASE model (faster, more stable)...')\n",
    "\n",
    "processor = TrOCRProcessor.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Load model directly to GPU without any lazy loading\n",
    "if torch.cuda.is_available():\n",
    "    print('Loading directly to GPU...')\n",
    "    # Method 1: Direct GPU loading\n",
    "    model = VisionEncoderDecoderModel.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        torch_dtype=torch.float16\n",
    "    ).to(device)\n",
    "else:\n",
    "    model = VisionEncoderDecoderModel.from_pretrained(MODEL_NAME)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Verify all parameters are on correct device\n",
    "print('\\nâœ… Verifying model placement...')\n",
    "sample_param = next(model.parameters())\n",
    "print(f'Model device: {sample_param.device}')\n",
    "print(f'Model dtype: {sample_param.dtype}')\n",
    "\n",
    "# Check if any parameters are on meta device\n",
    "meta_params = [name for name, param in model.named_parameters() if param.device.type == 'meta']\n",
    "if meta_params:\n",
    "    print(f'âš ï¸ WARNING: Found {len(meta_params)} parameters on meta device!')\n",
    "    print('First few:', meta_params[:5])\n",
    "else:\n",
    "    print('âœ… All parameters loaded correctly!')\n",
    "\n",
    "print('\\nâœ… TrOCR BASE model ready!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbce45fb-161d-4552-8774-ad661f31812d",
   "metadata": {},
   "source": [
    "## Step 3: Load Your Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6047506a-52a3-4f6c-8b64-2f9dd348a7d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T19:55:40.080905Z",
     "iopub.status.busy": "2026-02-15T19:55:40.080310Z",
     "iopub.status.idle": "2026-02-15T19:55:40.134221Z",
     "shell.execute_reply": "2026-02-15T19:55:40.133382Z",
     "shell.execute_reply.started": "2026-02-15T19:55:40.080874Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 727\n",
      "Validation samples: 146\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "BASE_PATH = '/kaggle/input/datasets/ayuuub/dataset/dataset/'\n",
    "IMG_DIR = os.path.join(BASE_PATH, 'images')\n",
    "labels_path = os.path.join(BASE_PATH, 'labels.csv')\n",
    "\n",
    "df = pd.read_csv(labels_path)\n",
    "df = df[df['text'].str.strip() != ''].reset_index(drop=True)\n",
    "\n",
    "MAX_TEXT_LEN = 130\n",
    "df = df[df['text'].str.len() <= MAX_TEXT_LEN].reset_index(drop=True)\n",
    "\n",
    "print(f'Total samples: {len(df)}')\n",
    "\n",
    "# Take validation set\n",
    "train_size = int(0.8 * len(df))\n",
    "val_df = df.iloc[train_size:].reset_index(drop=True)\n",
    "\n",
    "print(f'Validation samples: {len(val_df)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd6d31e-7e14-496e-ae8e-cc9708673cb0",
   "metadata": {},
   "source": [
    "## Step 4: Run TrOCR on Validation Set\n",
    "\n",
    "**This takes ~10-15 minutes for 2000 images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26fcef45-032d-4636-b389-9f8257462ad6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T19:55:40.658284Z",
     "iopub.status.busy": "2026-02-15T19:55:40.657707Z",
     "iopub.status.idle": "2026-02-15T19:55:58.209179Z",
     "shell.execute_reply": "2026-02-15T19:55:58.208388Z",
     "shell.execute_reply.started": "2026-02-15T19:55:40.658254Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Running TrOCR evaluation...\n",
      "\n",
      "Processed 100/146 images...\n",
      "\n",
      "âœ… Evaluation complete!\n"
     ]
    }
   ],
   "source": [
    "print('ğŸš€ Running TrOCR evaluation...\\n')\n",
    "\n",
    "all_predictions = []\n",
    "all_targets = []\n",
    "\n",
    "correct_chars = 0\n",
    "total_chars = 0\n",
    "\n",
    "for idx, row in val_df.iterrows():\n",
    "    img_path = os.path.join(IMG_DIR, row['file_name'])\n",
    "    true_text = row['text']\n",
    "    \n",
    "    try:\n",
    "        # Load image\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        # Process image and move to GPU\n",
    "        pixel_values = processor(image, return_tensors='pt').pixel_values.to(device)\n",
    "\n",
    "        # Generate prediction\n",
    "        with torch.no_grad():\n",
    "            generated_ids = model.generate(pixel_values)\n",
    "\n",
    "        pred_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "        all_predictions.append(pred_text)\n",
    "        all_targets.append(true_text)\n",
    "\n",
    "        # Character accuracy\n",
    "        correct = sum(1 for a, b in zip(pred_text, true_text) if a == b)\n",
    "        correct_chars += correct\n",
    "        total_chars += len(true_text)\n",
    "        \n",
    "        # Progress indicator\n",
    "        if (idx + 1) % 100 == 0:\n",
    "            print(f'Processed {idx + 1}/{len(val_df)} images...')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error on {img_path}: {e}\")\n",
    "        continue\n",
    "\n",
    "print('\\nâœ… Evaluation complete!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82c0acb-e718-4ed0-a1ee-22363df45068",
   "metadata": {},
   "source": [
    "## Step 5: Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68831c0f-98ad-4238-90e9-1dcdaa4a629a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T19:55:58.210662Z",
     "iopub.status.busy": "2026-02-15T19:55:58.210358Z",
     "iopub.status.idle": "2026-02-15T19:55:58.216099Z",
     "shell.execute_reply": "2026-02-15T19:55:58.215315Z",
     "shell.execute_reply.started": "2026-02-15T19:55:58.210637Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ğŸ¯ TrOCR RESULTS\n",
      "================================================================================\n",
      "Character Accuracy: 0.53%\n",
      "Perfect Match: 0.00%\n",
      "Total Samples: 146\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "char_accuracy = (correct_chars / total_chars * 100) if total_chars > 0 else 0\n",
    "\n",
    "# Calculate perfect matches\n",
    "perfect = sum(1 for pred, true in zip(all_predictions, all_targets) if pred == true)\n",
    "perfect_acc = (perfect / len(all_targets) * 100) if len(all_targets) > 0 else 0\n",
    "\n",
    "print(f'\\n{'='*80}')\n",
    "print(f'ğŸ¯ TrOCR RESULTS')\n",
    "print(f'{'='*80}')\n",
    "print(f'Character Accuracy: {char_accuracy:.2f}%')\n",
    "print(f'Perfect Match: {perfect_acc:.2f}%')\n",
    "print(f'Total Samples: {len(all_targets)}')\n",
    "print(f'{'='*80}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7444bda4-eead-4f6f-a525-ac8e0e07658f",
   "metadata": {},
   "source": [
    "## Step 6: Sample Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1358f484-0e13-4dd5-a766-90fa86fcc91b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T19:55:58.217294Z",
     "iopub.status.busy": "2026-02-15T19:55:58.216976Z",
     "iopub.status.idle": "2026-02-15T19:55:58.227786Z",
     "shell.execute_reply": "2026-02-15T19:55:58.227195Z",
     "shell.execute_reply.started": "2026-02-15T19:55:58.217259Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Predictions:\n",
      "\n",
      "====================================================================================================\n",
      "Sample 1 | Accuracy: 0.0%\n",
      "  True: LIST_0 â† [ 22 , 35 , 2 , 34 , 11 ]\n",
      "VAR_0 â† 1\n",
      "pour IDX_0 dans LIST_0 faire \n",
      "\tVAR_0 â† ( VAR_0 * LIST_0\n",
      "  Pred: ***\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 2 | Accuracy: 0.0%\n",
      "  True: LIST_0 â† [ 70 , 79 , 81 , 89 ]\n",
      "VAR_0 â† taille ( LIST_0 )\n",
      "  Pred: GST-95-TABLE CUST :8)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 3 | Accuracy: 0.0%\n",
      "  True: LIST_0 â† [ 64 , 56 , 114 , 50 , 122 , 81 , 107 , 88 , 79 , 105 , 86 , 73 , 59 , 102 , 101 , 63 , 80 \n",
      "  Pred: WELLOW, M.M.M.M.M.M.S.M.M\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 4 | Accuracy: 0.0%\n",
      "  True: LIST_0 â† [ 56 , 19 , 38 , 31 , 97 , 92 ]\n",
      "VAR_0 â† 0\n",
      "pour IDX_0 dans LIST_0 faire \n",
      "\tVAR_0 â† ( VAR_0 + \n",
      "  Pred: ***\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 5 | Accuracy: 0.0%\n",
      "  True: LIST_0 â† [ 93 , 153 , 173 , 157 , 93 , 55 ]\n",
      "VAR_0 â† 1\n",
      "pour IDX_0 dans LIST_0 faire \n",
      "\tVAR_0 â† ( VAR_0\n",
      "  Pred: ***\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 6 | Accuracy: 0.0%\n",
      "  True: algorithme\n",
      "\tVAR_0 â† ( 29 - 70 )\n",
      "si ( ( ( 82 + VAR_2 ) > ( 83 + VAR_3 ) ) ) alors \n",
      "\tVAR_4 â† 44\n",
      "sinon \n",
      "  Pred: ***\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 7 | Accuracy: 0.0%\n",
      "  True: algorithme\n",
      "\tsi ( ( ( 19 - VAR_0 ) < ( 88 / VAR_1 ) ) ) alors \n",
      "\tVAR_2 â† 47\n",
      "sinon \n",
      "\tVAR_3 â† 20fin si\n",
      "V\n",
      "  Pred: ***\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 8 | Accuracy: 0.0%\n",
      "  True: LIST_0 â† [ 20 , 35 , 34 , 42 , 35 , 16 ]\n",
      "VAR_0 â† 0\n",
      "pour IDX_0 dans LIST_0 faire \n",
      "\tVAR_0 â† ( VAR_0 + \n",
      "  Pred: *** ***\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 9 | Accuracy: 0.0%\n",
      "  True: algorithme\n",
      "\tVAR_1 â† ( ( 49 - 21 ) + ( 0 - 16 ) )\n",
      "fin\n",
      "  Pred: ***\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 10 | Accuracy: 0.9%\n",
      "  True: algorithme\n",
      "\tVAR_0 â† ( VAR_1 * 20 )\n",
      "si ( ( ( 60 mod 20 ) > ( VAR_3 - VAR_4 ) ) ) alors \n",
      "\tVAR_5 â† 7fin\n",
      "  Pred: APPROVED (60) MAS) : ( VAR 3 - VAR_4) )\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 11 | Accuracy: 3.6%\n",
      "  True: LIST_0 â† [ 6 , 36 , 7 ]\n",
      "VAR_0 â† 1\n",
      "pour IDX_0 dans LIST_0 faire \n",
      "\tVAR_0 â† ( VAR_0 * LIST_0 [ IDX_0 ] \n",
      "  Pred: *** WEEK OF RECEIPT @ FILLO ( 10%-0 1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 12 | Accuracy: 2.6%\n",
      "  True: LIST_0 â† [ 69 , 82 , 89 , 78 , 86 , 68 , 73 , 70 ]\n",
      "VAR_0 â† taille ( LIST_0 )\n",
      "  Pred: UST-02-TELLE (2.89-18) 86,68.73\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 13 | Accuracy: 0.0%\n",
      "  True: algorithme\n",
      "\tLIST_0 â† [ 3 , 82 , 54 ]\n",
      "VAR_0 â† 4\n",
      "pour IDX_0 dans LIST_0 faire \n",
      "\tVAR_0 â† ( VAR_0 * LIST\n",
      "  Pred: ***\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 14 | Accuracy: 0.0%\n",
      "  True: LIST_0 â† [ 17 , 32 , 44 ]\n",
      "VAR_0 â† 1\n",
      "pour IDX_0 dans LIST_0 faire \n",
      "\tVAR_0 â† ( VAR_0 * LIST_0 [ IDX_0 \n",
      "  Pred: ***\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 15 | Accuracy: 0.0%\n",
      "  True: algorithme\n",
      "\tLIST_0 â† [ 73 , 25 , 25 ]\n",
      "VAR_0 â† 4\n",
      "pour IDX_0 dans LIST_0 faire \n",
      "\tVAR_0 â† ( VAR_0 * LIS\n",
      "  Pred: ***\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 16 | Accuracy: 0.0%\n",
      "  True: algorithme\n",
      "\tLIST_0 â† [ 16 , 5 , 4 ]\n",
      "VAR_0 â† 9\n",
      "pour IDX_0 dans LIST_0 faire \n",
      "\tVAR_0 â† ( VAR_0 * LIST_\n",
      "  Pred: ***\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 17 | Accuracy: 6.7%\n",
      "  True: LIST_0 â† [ 86 , 118 , 118 , 106 , 82 , 69 , 83 , 94 , 122 , 83 , 93 , 92 , 87 ]\n",
      "VAR_0 â† taille ( LIS\n",
      "  Pred: VSR: (ML) UST @ , 06 , 82 , 63 , 84 , 122 ,\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 18 | Accuracy: 0.0%\n",
      "  True: algorithme\n",
      "\tVAR_0 â† ( VAR_1 mod VAR_2 )\n",
      "VAR_4 â† ( ( 57 / VAR_5 ) / ( VAR_6 + 68 ) )\n",
      "fin\n",
      "  Pred: ***\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 19 | Accuracy: 0.0%\n",
      "  True: LIST_0 â† [ 4 , 7 , 15 , 14 ]\n",
      "VAR_0 â† 0\n",
      "pour IDX_0 dans LIST_0 faire \n",
      "\tVAR_0 â† ( VAR_0 + LIST_0 [ IDX\n",
      "  Pred: ***\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 20 | Accuracy: 0.0%\n",
      "  True: algorithme\n",
      "\tsi ( ( ( VAR_2 / VAR_3 ) â‰¥ ( 51 - VAR_4 ) ) ) alors \n",
      "\tVAR_5 â† 9\n",
      "sinon \n",
      "\tVAR_6 â† 10fin si\n",
      "  Pred: ***\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "âœ… Done!\n"
     ]
    }
   ],
   "source": [
    "print('Sample Predictions:\\n')\n",
    "print('='*100)\n",
    "\n",
    "for i in range(min(20, len(all_predictions))):\n",
    "    true_text = all_targets[i]\n",
    "    pred_text = all_predictions[i]\n",
    "    \n",
    "    correct = sum(1 for a, b in zip(true_text, pred_text) if a == b)\n",
    "    sample_acc = (correct / len(true_text) * 100) if len(true_text) > 0 else 0\n",
    "    \n",
    "    print(f'Sample {i+1} | Accuracy: {sample_acc:.1f}%')\n",
    "    print(f'  True: {true_text[:100]}')\n",
    "    print(f'  Pred: {pred_text[:100]}')\n",
    "    print('-'*100)\n",
    "\n",
    "print(f'\\nâœ… Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33be7fd6-b499-45fc-a142-02dbcecd98ca",
   "metadata": {},
   "source": [
    "## Bonus: Save Model for Reuse\n",
    "\n",
    "If TrOCR works well, save it for later use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "524b65c9-8b84-47cb-ac3a-a0e7957292c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T19:07:16.841220Z",
     "iopub.status.busy": "2026-02-15T19:07:16.840907Z",
     "iopub.status.idle": "2026-02-15T19:07:18.974569Z",
     "shell.execute_reply": "2026-02-15T19:07:18.973928Z",
     "shell.execute_reply.started": "2026-02-15T19:07:16.841194Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model saved!\n"
     ]
    }
   ],
   "source": [
    "# Save TrOCR model\n",
    "model.save_pretrained('./trocr_model')\n",
    "processor.save_pretrained('./trocr_processor')\n",
    "\n",
    "print('âœ… Model saved!')\n",
    "\n",
    "# Later, load it:\n",
    "# model = VisionEncoderDecoderModel.from_pretrained('./trocr_model')\n",
    "# processor = TrOCRProcessor.from_pretrained('./trocr_processor')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e263e985",
   "metadata": {},
   "source": [
    "# ğŸ”¥ Fine-tune TrOCR on Pseudocode\n",
    "\n",
    "**Let's train TrOCR to understand your pseudocode!**\n",
    "\n",
    "The pre-trained model failed because it only knows English. We'll fine-tune it on your dataset to teach it pseudocode syntax.\n",
    "\n",
    "## Why Fine-tune?\n",
    "- âœ… Learns pseudocode: `â†`, `pour...faire`, `VAR_0`, etc.\n",
    "- âœ… Uses pre-trained vision encoder (saves training time)\n",
    "- âœ… Should beat your 49% with less training\n",
    "- âœ… Expected: 60-70% after 10-20 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52680de2",
   "metadata": {},
   "source": [
    "## Step 1: Install Training Dependencies (OPTIONAL)\n",
    "\n",
    "**Note:** The training code below uses a **simple manual loop** that doesn't need special dependencies!  \n",
    "You can **skip cells 19-21** and go directly to Step 2 if you want to avoid dependency issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd3670d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T19:56:07.612222Z",
     "iopub.status.busy": "2026-02-15T19:56:07.611675Z",
     "iopub.status.idle": "2026-02-15T19:56:37.459233Z",
     "shell.execute_reply": "2026-02-15T19:56:37.458401Z",
     "shell.execute_reply.started": "2026-02-15T19:56:07.612182Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping evaluate as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m90.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchtune 0.6.1 requires datasets, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m302.4/302.4 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m251.2/251.2 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m172.0/172.0 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m146.7/146.7 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "bigframes 2.26.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\n",
      "cudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\n",
      "gradio 5.49.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.5 which is incompatible.\n",
      "bigframes 2.26.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\n",
      "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.3.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hâœ… Compatible versions installed!\n",
      "\n",
      "âš ï¸ VERY IMPORTANT: Restart runtime now!\n",
      "After restart, continue from the cell that loads the base model (cell 6).\n"
     ]
    }
   ],
   "source": [
    "# ğŸ”¥ Install fully compatible versions for TrOCR fine-tuning\n",
    "\n",
    "# Uninstall problematic packages\n",
    "!pip uninstall -y transformers accelerate datasets evaluate tokenizers peft -q\n",
    "\n",
    "# Install compatible stack (tested combination)\n",
    "!pip install -q transformers==4.41.0\n",
    "!pip install -q accelerate==0.30.0  # Has clear_device_cache\n",
    "!pip install -q peft==0.11.0  # Compatible with accelerate 0.30\n",
    "!pip install -q datasets==2.19.1\n",
    "!pip install -q evaluate==0.4.1\n",
    "\n",
    "print('âœ… Compatible versions installed!')\n",
    "print('\\nâš ï¸ VERY IMPORTANT: Restart runtime now!')\n",
    "print('After restart, continue from the cell that loads the base model (cell 6).')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f351ae",
   "metadata": {},
   "source": [
    "**ğŸ’¡ Troubleshooting:** If you still get import errors, run this cell to downgrade peft:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46c7180d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T19:56:43.128770Z",
     "iopub.status.busy": "2026-02-15T19:56:43.127932Z",
     "iopub.status.idle": "2026-02-15T19:56:43.201286Z",
     "shell.execute_reply": "2026-02-15T19:56:43.200524Z",
     "shell.execute_reply.started": "2026-02-15T19:56:43.128733Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¦ Installed versions:\n",
      "transformers: 4.57.1\n",
      "accelerate: 1.11.0\n",
      "datasets: 4.4.2\n",
      "evaluate: 0.4.1\n",
      "peft: 0.17.1\n",
      "\n",
      "âœ… All packages loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Verify installed versions\n",
    "import transformers\n",
    "import accelerate\n",
    "import datasets\n",
    "import evaluate\n",
    "\n",
    "print('ğŸ“¦ Installed versions:')\n",
    "print(f'transformers: {transformers.__version__}')\n",
    "print(f'accelerate: {accelerate.__version__}')\n",
    "print(f'datasets: {datasets.__version__}')\n",
    "print(f'evaluate: {evaluate.__version__}')\n",
    "\n",
    "try:\n",
    "    import peft\n",
    "    print(f'peft: {peft.__version__}')\n",
    "except:\n",
    "    print('peft: not installed')\n",
    "\n",
    "print('\\nâœ… All packages loaded successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7da9dc",
   "metadata": {},
   "source": [
    "## Step 2: Prepare Dataset for Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03543767",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T19:56:49.837838Z",
     "iopub.status.busy": "2026-02-15T19:56:49.837316Z",
     "iopub.status.idle": "2026-02-15T19:56:49.874117Z",
     "shell.execute_reply": "2026-02-15T19:56:49.873305Z",
     "shell.execute_reply.started": "2026-02-15T19:56:49.837806Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 581\n",
      "Validation samples: 146\n",
      "\n",
      "âœ… Datasets created!\n",
      "Sample from training dataset:\n",
      "  Pixel values shape: torch.Size([3, 384, 384])\n",
      "  Labels shape: torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "# Create train/val split\n",
    "train_df = df.iloc[:train_size].reset_index(drop=True)\n",
    "val_df = df.iloc[train_size:].reset_index(drop=True)\n",
    "\n",
    "print(f'Training samples: {len(train_df)}')\n",
    "print(f'Validation samples: {len(val_df)}')\n",
    "\n",
    "# Custom Dataset class for TrOCR\n",
    "class TrOCRDataset(Dataset):\n",
    "    def __init__(self, df, processor, img_dir, max_target_length=128):\n",
    "        self.df = df\n",
    "        self.processor = processor\n",
    "        self.img_dir = img_dir\n",
    "        self.max_target_length = max_target_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Get file name and text\n",
    "        file_name = self.df.loc[idx, 'file_name']\n",
    "        text = self.df.loc[idx, 'text']\n",
    "        \n",
    "        # Read image\n",
    "        image_path = os.path.join(self.img_dir, file_name)\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        \n",
    "        # Process image\n",
    "        pixel_values = self.processor(image, return_tensors='pt').pixel_values\n",
    "        \n",
    "        # Process text (tokenize)\n",
    "        labels = self.processor.tokenizer(\n",
    "            text, \n",
    "            padding='max_length', \n",
    "            max_length=self.max_target_length,\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        ).input_ids\n",
    "        \n",
    "        # Remove batch dimension\n",
    "        pixel_values = pixel_values.squeeze()\n",
    "        labels = labels.squeeze()\n",
    "        \n",
    "        # Replace padding token id's with -100 (ignored by loss)\n",
    "        labels[labels == self.processor.tokenizer.pad_token_id] = -100\n",
    "        \n",
    "        return {\n",
    "            'pixel_values': pixel_values,\n",
    "            'labels': labels\n",
    "        }\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = TrOCRDataset(train_df, processor, IMG_DIR)\n",
    "val_dataset = TrOCRDataset(val_df, processor, IMG_DIR)\n",
    "\n",
    "print(f'\\nâœ… Datasets created!')\n",
    "print(f'Sample from training dataset:')\n",
    "sample = train_dataset[0]\n",
    "print(f'  Pixel values shape: {sample[\"pixel_values\"].shape}')\n",
    "print(f'  Labels shape: {sample[\"labels\"].shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8500bacb",
   "metadata": {},
   "source": [
    "## Step 3: Setup Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a7d7770",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T19:56:53.355703Z",
     "iopub.status.busy": "2026-02-15T19:56:53.354956Z",
     "iopub.status.idle": "2026-02-15T19:56:54.388471Z",
     "shell.execute_reply": "2026-02-15T19:56:54.387771Z",
     "shell.execute_reply.started": "2026-02-15T19:56:53.355674Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Transformers trainer imported successfully!\n",
      "Loading fresh TrOCR model for fine-tuning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-printed and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model ready for fine-tuning!\n",
      "âœ… Training configuration set!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "    from transformers import default_data_collator\n",
    "    import evaluate\n",
    "    print('âœ… Transformers trainer imported successfully!')\n",
    "except ImportError as e:\n",
    "    print(f'âš ï¸ Import error: {e}')\n",
    "    print('Please run the troubleshooting cell above to fix version compatibility!')\n",
    "    raise\n",
    "\n",
    "# Load a fresh model for fine-tuning\n",
    "print('Loading fresh TrOCR model for fine-tuning...')\n",
    "model = VisionEncoderDecoderModel.from_pretrained('microsoft/trocr-base-printed')\n",
    "\n",
    "# Set special tokens\n",
    "model.config.decoder_start_token_id = processor.tokenizer.cls_token_id\n",
    "model.config.pad_token_id = processor.tokenizer.pad_token_id\n",
    "\n",
    "# Make sure vocab size is correctly set\n",
    "model.config.vocab_size = model.config.decoder.vocab_size\n",
    "\n",
    "# Move to GPU\n",
    "model = model.to(device)\n",
    "\n",
    "print('âœ… Model ready for fine-tuning!')\n",
    "\n",
    "# Training arguments\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir='./trocr-finetuned-pseudocode',\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    predict_with_generate=True,\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    logging_steps=50,\n",
    "    num_train_epochs=15,\n",
    "    learning_rate=5e-5,\n",
    "    fp16=True,  # Mixed precision training\n",
    "    save_total_limit=2,  # Only keep best 2 checkpoints\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='cer',  # Character Error Rate\n",
    "    greater_is_better=False,\n",
    "    warmup_steps=100,\n",
    "    report_to='none'  # Disable wandb/tensorboard\n",
    ")\n",
    "\n",
    "print('âœ… Training configuration set!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dad6a7",
   "metadata": {},
   "source": [
    "## Step 4: Setup Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c375b939",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T19:57:00.614407Z",
     "iopub.status.busy": "2026-02-15T19:57:00.613697Z",
     "iopub.status.idle": "2026-02-15T19:57:00.772836Z",
     "shell.execute_reply": "2026-02-15T19:57:00.771885Z",
     "shell.execute_reply.started": "2026-02-15T19:57:00.614376Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DownloadConfig' object has no attribute 'use_auth_token'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_55/3989477105.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load CER metric (Character Error Rate)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcer_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/evaluate/loading.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, config_name, module_type, process_id, num_process, cache_dir, experiment_id, keep_in_memory, download_config, download_mode, revision, **init_kwargs)\u001b[0m\n\u001b[1;32m    746\u001b[0m     \"\"\"\n\u001b[1;32m    747\u001b[0m     \u001b[0mdownload_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDownloadMode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownload_mode\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mDownloadMode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREUSE_DATASET_IF_EXISTS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m     evaluation_module = evaluation_module_factory(\n\u001b[0m\u001b[1;32m    749\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodule_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m     )\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/evaluate/loading.py\u001b[0m in \u001b[0;36mevaluation_module_factory\u001b[0;34m(path, module_type, revision, download_config, download_mode, force_local_path, dynamic_modules_path, **download_kwargs)\u001b[0m\n\u001b[1;32m    678\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mConnectionError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m             raise FileNotFoundError(\n\u001b[1;32m    682\u001b[0m                 \u001b[0;34mf\"Couldn't find a module script at {relative_to_absolute_path(combined_path)}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/evaluate/loading.py\u001b[0m in \u001b[0;36mevaluation_module_factory\u001b[0;34m(path, module_type, revision, download_config, download_mode, force_local_path, dynamic_modules_path, **download_kwargs)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                 \u001b[0mdownload_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m                                 \u001b[0mdynamic_modules_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdynamic_modules_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m                             ).get_module()\n\u001b[0m\u001b[1;32m    640\u001b[0m                         \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m                             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/evaluate/loading.py\u001b[0m in \u001b[0;36mget_module\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    477\u001b[0m         \u001b[0;31m# get script and other files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m             \u001b[0mlocal_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_loading_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFileNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m             \u001b[0;31m# if there is no file found with current revision tag try to load main\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/evaluate/loading.py\u001b[0m in \u001b[0;36mdownload_loading_script\u001b[0;34m(self, revision)\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdownload_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_desc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m             \u001b[0mdownload_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_desc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Downloading builder script\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcached_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mImportableModule\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/evaluate/utils/file_utils.py\u001b[0m in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, download_config, **download_kwargs)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0muse_etag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_etag\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mmax_retries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_auth_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m             \u001b[0mignore_url_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_url_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mdownload_desc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_desc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DownloadConfig' object has no attribute 'use_auth_token'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load CER metric (Character Error Rate)\n",
    "cer_metric = evaluate.load('cer')\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels_ids = pred.label_ids\n",
    "    pred_ids = pred.predictions\n",
    "    \n",
    "    # Decode predictions\n",
    "    pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    \n",
    "    # Replace -100 in labels with pad_token_id\n",
    "    labels_ids[labels_ids == -100] = processor.tokenizer.pad_token_id\n",
    "    \n",
    "    # Decode labels\n",
    "    label_str = processor.batch_decode(labels_ids, skip_special_tokens=True)\n",
    "    \n",
    "    # Compute CER (lower is better)\n",
    "    cer = cer_metric.compute(predictions=pred_str, references=label_str)\n",
    "    \n",
    "    # Compute character accuracy (higher is better)\n",
    "    total_chars = 0\n",
    "    correct_chars = 0\n",
    "    for pred, label in zip(pred_str, label_str):\n",
    "        correct = sum(1 for a, b in zip(pred, label) if a == b)\n",
    "        correct_chars += correct\n",
    "        total_chars += len(label)\n",
    "    \n",
    "    char_acc = (correct_chars / total_chars * 100) if total_chars > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'cer': cer,\n",
    "        'char_accuracy': char_acc\n",
    "    }\n",
    "\n",
    "print('âœ… Metrics configured!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c77fb0",
   "metadata": {},
   "source": [
    "## Step 5: Start Fine-tuning! ğŸš€\n",
    "\n",
    "**This will take ~15-30 minutes for 15 epochs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7e076bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-15T19:57:07.467071Z",
     "iopub.status.busy": "2026-02-15T19:57:07.466488Z",
     "iopub.status.idle": "2026-02-15T19:57:07.473744Z",
     "shell.execute_reply": "2026-02-15T19:57:07.472724Z",
     "shell.execute_reply.started": "2026-02-15T19:57:07.467039Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'compute_metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_55/1629977518.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0meval_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdata_collator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_data_collator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mcompute_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'compute_metrics' is not defined"
     ]
    }
   ],
   "source": [
    "# Initialize trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=default_data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "print('ğŸš€ Starting fine-tuning...\\n')\n",
    "\n",
    "# Train!\n",
    "train_results = trainer.train()\n",
    "\n",
    "print('\\nâœ… Fine-tuning complete!')\n",
    "print(f'Training loss: {train_results.training_loss:.4f}')\n",
    "print(f'Training time: {train_results.metrics[\"train_runtime\"]:.2f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72fbf98",
   "metadata": {},
   "source": [
    "## Step 6: Evaluate Fine-tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b798d268",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2026-02-15T19:07:36.611166Z",
     "iopub.status.idle": "2026-02-15T19:07:36.611545Z",
     "shell.execute_reply": "2026-02-15T19:07:36.611438Z",
     "shell.execute_reply.started": "2026-02-15T19:07:36.611421Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Evaluate on validation set\n",
    "print('ğŸ” Evaluating on validation set...\\n')\n",
    "\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "print('='*80)\n",
    "print('ğŸ¯ FINE-TUNED TrOCR RESULTS')\n",
    "print('='*80)\n",
    "print(f'Character Error Rate (CER): {eval_results[\"eval_cer\"]:.4f}')\n",
    "print(f'Character Accuracy: {eval_results[\"eval_char_accuracy\"]:.2f}%')\n",
    "print(f'Samples evaluated: {eval_results[\"eval_samples\"]}')\n",
    "print('='*80)\n",
    "\n",
    "# Compare with your custom model\n",
    "print('\\nğŸ“Š COMPARISON:')\n",
    "print(f'Your custom model: 49.43%')\n",
    "print(f'Fine-tuned TrOCR: {eval_results[\"eval_char_accuracy\"]:.2f}%')\n",
    "\n",
    "if eval_results[\"eval_char_accuracy\"] > 49.43:\n",
    "    print('\\nâœ… Fine-tuned TrOCR wins! ğŸ‰')\n",
    "else:\n",
    "    print('\\nğŸ¤” Your custom model is still better (more training needed?)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8319a2ff",
   "metadata": {},
   "source": [
    "## Step 7: Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8065d534",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2026-02-15T19:07:36.612898Z",
     "iopub.status.idle": "2026-02-15T19:07:36.613170Z",
     "shell.execute_reply": "2026-02-15T19:07:36.613065Z",
     "shell.execute_reply.started": "2026-02-15T19:07:36.613045Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Test on a few random samples\n",
    "print('ğŸ”¬ Testing on sample images...\\n')\n",
    "print('='*100)\n",
    "\n",
    "# Get model from trainer (best checkpoint)\n",
    "finetuned_model = trainer.model\n",
    "finetuned_model.eval()\n",
    "\n",
    "# Test on 10 random validation samples\n",
    "import random\n",
    "test_indices = random.sample(range(len(val_df)), min(10, len(val_df)))\n",
    "\n",
    "for i, idx in enumerate(test_indices):\n",
    "    img_path = os.path.join(IMG_DIR, val_df.loc[idx, 'file_name'])\n",
    "    true_text = val_df.loc[idx, 'text']\n",
    "    \n",
    "    try:\n",
    "        # Load and process image\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        pixel_values = processor(image, return_tensors='pt').pixel_values.to(device)\n",
    "        \n",
    "        # Generate prediction\n",
    "        with torch.no_grad():\n",
    "            generated_ids = finetuned_model.generate(pixel_values)\n",
    "        \n",
    "        pred_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        correct = sum(1 for a, b in zip(pred_text, true_text) if a == b)\n",
    "        accuracy = (correct / len(true_text) * 100) if len(true_text) > 0 else 0\n",
    "        \n",
    "        print(f'Sample {i+1} | Accuracy: {accuracy:.1f}%')\n",
    "        print(f'  True: {true_text[:80]}...')\n",
    "        print(f'  Pred: {pred_text[:80]}...')\n",
    "        print('-'*100)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'Error: {e}')\n",
    "        continue\n",
    "\n",
    "print('\\nâœ… Testing complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecaed60",
   "metadata": {},
   "source": [
    "## Step 8: Save Fine-tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a1e16f",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2026-02-15T19:07:36.614272Z",
     "iopub.status.idle": "2026-02-15T19:07:36.614553Z",
     "shell.execute_reply": "2026-02-15T19:07:36.614452Z",
     "shell.execute_reply.started": "2026-02-15T19:07:36.614436Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Save the fine-tuned model\n",
    "save_path = './trocr_finetuned_pseudocode'\n",
    "\n",
    "print(f'ğŸ’¾ Saving fine-tuned model to {save_path}...')\n",
    "\n",
    "finetuned_model.save_pretrained(save_path)\n",
    "processor.save_pretrained(save_path)\n",
    "\n",
    "print('âœ… Model saved!')\n",
    "\n",
    "# How to load it later:\n",
    "print(f'\\nğŸ“ To load this model later, use:')\n",
    "print(f'model = VisionEncoderDecoderModel.from_pretrained(\"{save_path}\")')\n",
    "print(f'processor = TrOCRProcessor.from_pretrained(\"{save_path}\")')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dfb9af",
   "metadata": {},
   "source": [
    "## ğŸ† Final Comparison\n",
    "\n",
    "Compare all models side-by-side!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de91a381",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2026-02-15T19:07:36.615889Z",
     "iopub.status.idle": "2026-02-15T19:07:36.616177Z",
     "shell.execute_reply": "2026-02-15T19:07:36.616071Z",
     "shell.execute_reply.started": "2026-02-15T19:07:36.616053Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create comparison table\n",
    "results = {\n",
    "    'Model': [\n",
    "        'Original CRNN',\n",
    "        'Your scratch v1',\n",
    "        'Improved scratch',\n",
    "        'TrOCR Pre-trained',\n",
    "        'TrOCR Fine-tuned'\n",
    "    ],\n",
    "    'Accuracy': [\n",
    "        '13-14%',\n",
    "        '32%',\n",
    "        '49.43%',\n",
    "        '0.53%',\n",
    "        f'{eval_results[\"eval_char_accuracy\"]:.2f}%'  # From training\n",
    "    ],\n",
    "    'Training Time': [\n",
    "        '40 epochs',\n",
    "        '47 epochs',\n",
    "        '108 epochs',\n",
    "        'None',\n",
    "        f'{train_results.metrics[\"train_runtime\"]/60:.1f} min'\n",
    "    ],\n",
    "    'Notes': [\n",
    "        'Poor baseline',\n",
    "        'Good progress',\n",
    "        'Best custom model',\n",
    "        'Failed - wrong domain',\n",
    "        'Trained on pseudocode'\n",
    "    ]\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(results)\n",
    "print('\\n' + '='*100)\n",
    "print('ğŸ“Š MODEL COMPARISON')\n",
    "print('='*100)\n",
    "print(comparison_df.to_string(index=False))\n",
    "print('='*100)\n",
    "\n",
    "# Determine winner\n",
    "finetuned_acc = eval_results[\"eval_char_accuracy\"]\n",
    "if finetuned_acc > 49.43:\n",
    "    print(f'\\nğŸ† WINNER: Fine-tuned TrOCR ({finetuned_acc:.2f}%)')\n",
    "    print('The fine-tuned model learned pseudocode successfully!')\n",
    "elif finetuned_acc > 40:\n",
    "    print(f'\\nğŸ¤ CLOSE: Fine-tuned TrOCR is competitive ({finetuned_acc:.2f}% vs 49.43%)')\n",
    "    print('Try training longer or adjusting hyperparameters!')\n",
    "else:\n",
    "    print(f'\\nğŸ’ª WINNER: Your Custom Model (49.43%)')\n",
    "    print('Your scratch model is still better - it was optimized specifically for this task!')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 9491824,
     "sourceId": 14840602,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9494133,
     "sourceId": 14844163,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31259,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
